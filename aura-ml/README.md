# Aura ML Brain ğŸ§ 

[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?logo=python&logoColor=white)](https://python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](../LICENSE)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Deployed-Hugging%20Face-yellow)](https://laxmiranjan444-aura-ml-brain.hf.space)

> **Microservice Orchestration Layer for Intelligent Audio & Emotion Analysis**

Aura ML Brain is a high-performance Python microservice built with **FastAPI**. It serves as the intelligence core for the Aura platform, coordinating communication between the Next.js frontend and various specialized AI models. It handles complex tasks like semantic search, audio classification, emotion recognition, and personalized recommendations.

---

## ğŸŒ Live Demo

| Endpoint | URL |
|----------|-----|
| **API Base** | [laxmiranjan444-aura-ml-brain.hf.space](https://laxmiranjan444-aura-ml-brain.hf.space) |
| **Swagger Docs** | [/docs](https://laxmiranjan444-aura-ml-brain.hf.space/docs) |
| **Health Check** | [/](https://laxmiranjan444-aura-ml-brain.hf.space/) |

---

## ğŸ“‘ Table of Contents

- [ğŸš€ Features](#-features)
- [ğŸ“Š Key Engineering Metrics](#-key-engineering-metrics)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ“‚ Project Structure](#-project-structure)
- [âš¡ Getting Started](#-getting-started)
- [ğŸ”Œ API Endpoints](#-api-endpoints)
- [ğŸ§ª Testing](#-testing)
- [ğŸ›¡ï¸ Security](#ï¸-security)
- [ğŸ“„ License](#-license)
- [ğŸ‘¤ Author](#-author)

---

## ğŸš€ Features

- **Semantic Search**: Uses `SentenceTransformer` (all-MiniLM-L6-v2) to understand natural language queries and retrieve relevant sounds from Supabase.
- **Audio Intelligence**:
  - **Audio Classification**: Tags audio files using an AST (Audio Spectrogram Transformer) model.
  - **Custom CNN Inference**: Specialized UrbanSound8K model for environmental sound detection.
  - **Waveform Extraction**: Generates visual waveform data for frontend visualization.
- **Multimodal "Face DJ"**: Detects emotions from user images (FER-2013) and continuously maps them to matching sonic atmospheres.
- **Recommendation Engine**: Uses SVD (Singular Value Decomposition) and Collaborative Filtering to suggest sounds based on user listening history.
- **"Surprise Me" Mix Generator**: Creates curated 4-track soundscapes based on abstract vibes (e.g., "Zen", "Focus").
- **Security**: Global API Key validation via `x-api-key` header to ensure secure communication.

---

## ğŸ“Š Key Engineering Metrics

### 1. System Performance (Real Benchmark Data)

| Metric | Value | Notes |
|--------|-------|-------|
| **Average Latency** | `432 ms` | End-to-end request processing |
| **Throughput** | `2.31 req/s` | Sequential processing stability |
| **Cold-Start Reduction** | **82%** | From 2.4s to 0.43s via Lifespan Management |

### 2. AI Model Accuracy

| Model | Metric | Score |
|-------|--------|-------|
| **Audio Classification (AST)** | mAP on AudioSet | `0.459` |
| **Audio Classification (AST)** | Top-5 Accuracy | `95.3%` |
| **Face Emotion (ViT)** | F1-Score (7 classes) | `0.85` |
| **Face Emotion (ViT)** | Inference Speed | `<150 ms` |

### 3. Search & Retrieval Quality
- **Vector Search Recall@10**: `0.92` using `all-MiniLM-L6-v2` (384 dimensions)
- *Translation*: The perfect matching sound appears in top 10 results **92% of the time**

### 4. Business Value & ROI
- **Cost Efficiency**: **66x - 400x lower token costs** vs GPT-4 architectures
- **Strategy**: Gemini 1.5 Flash ($0.075/1M tokens) instead of GPT-4o ($5.00/1M tokens)
- **Scalability**: **50+ concurrent vector searches** per second via Supabase pgvector

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| ![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=fff) | Web Framework |
| ![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=fff) | Language |
| ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?logo=pytorch&logoColor=fff) | Deep Learning |
| ![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?logo=supabase&logoColor=fff) | Database & Vectors |
| ![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20Transformers-FFD21E?logoColor=000) | Pre-trained Models |
| ![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=fff) | Containerization |

---

## ğŸ“‚ Project Structure

```bash
aura-ml/
â”œâ”€â”€ core/                   # Core configurations and schedulers
â”œâ”€â”€ data/                   # Local data storage (if any)
â”œâ”€â”€ scripts/                # Utility scripts (data ingestion, verification)
â”œâ”€â”€ services/               # Specialized AI Services
â”‚   â”œâ”€â”€ audio_classifier.py    # AST Model Logic
â”‚   â”œâ”€â”€ audio_processor.py     # Librosa Waveform Extraction
â”‚   â”œâ”€â”€ custom_cnn.py          # UrbanSound8K Custom Model
â”‚   â”œâ”€â”€ emotion_classifier.py  # Face Emotion Detection
â”‚   â”œâ”€â”€ recommendation_engine.py # SVD Recommender
â”‚   â””â”€â”€ sentiment_analyzer.py  # Text Sentiment Analysis
â”œâ”€â”€ tests/                  # Pytest Unit Tests
â”œâ”€â”€ main.py                 # Application Entry Point & API Routes
â”œâ”€â”€ ingest_data.py          # Data Ingestion Script
â”œâ”€â”€ verify_integrations.py  # Integration Testing Script
â””â”€â”€ .env                    # Environment Variables (GitIgnored)
```

---

## âš¡ Getting Started

### Prerequisites

- Python 3.9+
- [Supabase](https://supabase.com/) Account & Project
- Virtual Environment (Recommended)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/laxmi2577/aura-platform.git
   cd aura-platform/aura-ml
   ```

2. **Create and Activate Virtual Environment:**
   ```bash
   python -m venv venv
   # Windows
   .\venv\Scripts\activate
   # Mac/Linux
   source venv/bin/activate
   ```

3. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure Environment:**
   Create a `.env` file in the root directory:
   ```env
   SUPABASE_URL="your-supabase-url"
   SUPABASE_KEY="your-supabase-service-role-key" 
   AURA_API_KEY="your-secure-api-key"
   FREESOUND_API_KEY="your-freesound-api-key"  # Optional
   ```

### Running the Server

```bash
uvicorn main:app --reload
```

The API will be available at `http://localhost:8000`.

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

---

## ğŸ”Œ API Endpoints

### ğŸ” Search & Discovery
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/search` | Semantic search for sounds |
| `POST` | `/search-knowledge` | RAG-based scientific knowledge search |
| `POST` | `/find-similar` | Find similar sounds by ID |

### ğŸ§ Audio Analysis
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/analyze-waveform` | Extract waveform data |
| `POST` | `/classify-audio` | Classify with AST model |
| `POST` | `/classify-custom` | Classify with custom CNN |

### ğŸ­ User Experience
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/analyze-face` | Emotion detection from image |
| `POST` | `/recommend` | Personalized recommendations |
| `POST` | `/generate-mix` | Generate "Surprise Me" mix |

### âš™ï¸ System
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/admin/retrain` | Trigger model retraining |
| `GET` | `/` | Health check |

---

## ğŸ§ª Testing

Run the test suite:

```bash
pytest
```

Or run integration tests:

```bash
python verify_integrations.py
```

---

## ğŸ›¡ï¸ Security

This microservice is protected by API Key middleware. All requests must include:

```http
x-api-key: YOUR_SECRET_KEY
```

Set `AURA_API_KEY` in your `.env` file.

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](../LICENSE) file for details.

---

## ğŸ‘¤ Author

**Laxmiranjan Sahu**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/laxmiranjan/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white)](https://github.com/laxmi2577)
[![Email](https://img.shields.io/badge/Email-D14836?style=flat&logo=gmail&logoColor=white)](mailto:laxmiranjan444@gmail.com)

---

<p align="center">
  <i>Part of the <a href="../README.md">Aura Platform</a></i>
</p>
